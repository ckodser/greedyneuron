{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# secret_value_0 = user_secrets.get_secret(\"wb\")\n",
    "#\n",
    "# import os\n",
    "#\n",
    "# os.environ[\"WANDB_API_KEY\"] = secret_value_0\n",
    "# os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "#\n",
    "# import wandb\n",
    "\n",
    "# wandb.init(project=\"test3\", entity=\"ckodserteam\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:16:50.450616Z",
     "iopub.execute_input": "2022-12-30T20:16:50.451326Z",
     "iopub.status.idle": "2022-12-30T20:16:50.729174Z",
     "shell.execute_reply.started": "2022-12-30T20:16:50.451286Z",
     "shell.execute_reply": "2022-12-30T20:16:50.728266Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    ConcatDataset,\n",
    "    Subset,\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    ")"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-12-30T20:16:54.133593Z",
     "iopub.execute_input": "2022-12-30T20:16:54.134445Z",
     "iopub.status.idle": "2022-12-30T20:16:54.141043Z",
     "shell.execute_reply.started": "2022-12-30T20:16:54.134406Z",
     "shell.execute_reply": "2022-12-30T20:16:54.139657Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def norm(A):\n",
    "    return torch.sum(A*A).item()\n",
    "\n",
    "class LinearGreedy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight):\n",
    "        ctx.save_for_backward(input, weight)\n",
    "        return torch.matmul(input, torch.transpose(weight, 0, 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        '''\n",
    "        :param ctx:\n",
    "        :param grad_output:\n",
    "        :return: real gradient for myweight, cut effect of neurons when calculating input grad.\n",
    "        '''\n",
    "        eps = 1e-8\n",
    "        input, weight = ctx.saved_tensors\n",
    "        weight_grad_initial=torch.matmul(torch.transpose(grad_output, 0, 1), input)\n",
    "        grad_input_initial=torch.matmul(grad_output, weight)\n",
    "        f = torch.sum(weight_grad_initial*weight_grad_initial, dim=1)\n",
    "        f=torch.ones_like(f)\n",
    "        f_normalize=f/(torch.mean(f)+eps)\n",
    "        grad_output_normalized=grad_output/(f_normalize+eps)\n",
    "        grad_input=torch.matmul(grad_output_normalized, weight)\n",
    "        grad_weight=torch.matmul(torch.transpose(grad_output_normalized, 0, 1), input)\n",
    "\n",
    "        # print(\"weight_grad\", norm(weight_grad_initial), \"->\", norm(grad_weight))\n",
    "        # print(\"grad_input\", norm(grad_input_initial), \"->\", norm(grad_input))\n",
    "\n",
    "        return grad_input, grad_weight\n",
    "\n",
    "\n",
    "    \n",
    "class GreedyLinearMult(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        linear = nn.Linear(input_size, output_size)\n",
    "        self.weight = torch.nn.parameter.Parameter(data=linear.weight.clone(), requires_grad=True)\n",
    "        self.bias = torch.nn.parameter.Parameter(data=linear.bias.clone(), requires_grad=True)\n",
    "        self.register_parameter(\"Gweight\", self.weight)\n",
    "        self.register_parameter(\"Gbias\", self.bias)\n",
    "        with torch.no_grad():\n",
    "            self.bias_initial_norm=torch.linalg.norm(self.bias.data)\n",
    "            self.weigth_initial_norm=torch.linalg.matrix_norm(self.weight.data)\n",
    "        \n",
    "        \n",
    "    def record(self):\n",
    "        with torch.no_grad():\n",
    "            self.bias_initial_norm=torch.linalg.norm(self.mybias.data)\n",
    "            self.weigth_initial_norm=torch.linalg.matrix_norm(self.myweight.data)\n",
    "    \n",
    "    def normalize(self):\n",
    "        with torch.no_grad():\n",
    "            bias_norm=torch.linalg.norm(self.mybias.data)\n",
    "            weigth_norm=torch.linalg.matrix_norm(self.myweight.data)\n",
    "            self.myweight.data*=(self.weigth_initial_norm/weigth_norm)\n",
    "            self.mybias.data*=(self.bias_initial_norm/bias_norm)  \n",
    "            \n",
    "    def forward(self, input):\n",
    "        return LinearGreedy.apply(input, self.weight)+self.bias\n",
    "                \n",
    "class GLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, mode, activation):\n",
    "        super().__init__()\n",
    "        assert mode in [\"greedy\", \"normal\", \"intel\"]\n",
    "        self.mode=mode\n",
    "        self.activation=activation\n",
    "        \n",
    "        \n",
    "        if self.mode == \"normal\":\n",
    "            self.linear = nn.Linear(input_size, output_size)\n",
    "        else:\n",
    "            self.linear = GreedyLinearMult(input_size, output_size)\n",
    "        \n",
    "        if self.mode == \"intel\":\n",
    "            self.bn=nn.BatchNorm1d(output_size, affine=False)\n",
    "        \n",
    "    \n",
    "    def change_mode(self, new_mode):\n",
    "        self.mode=new_mode\n",
    "        if self.mode == \"intel\":\n",
    "            self.bn=nn.BatchNorm1d(output_size, affine=False)\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def forward(self, input: torch.tensor):\n",
    "        x = self.linear(input)\n",
    "        if self.mode == \"intel\":\n",
    "            x=self.bn(x)\n",
    "        if self.activation:\n",
    "            x=self.activation(x)\n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:11.043864Z",
     "iopub.execute_input": "2022-12-30T20:19:11.044256Z",
     "iopub.status.idle": "2022-12-30T20:19:11.063986Z",
     "shell.execute_reply.started": "2022-12-30T20:19:11.044221Z",
     "shell.execute_reply": "2022-12-30T20:19:11.062999Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#configs\n",
    "\n",
    "lr = 0.1\n",
    "epochs = 200\n",
    "batch_size = 512\n",
    "device = \"cuda\"\n",
    "dataset_name = \"FashionMNIST\"\n",
    "hidden_states=[1024*8,256*8*4,256*8*4,256*8*4,256*8, 128]\n",
    "mode=\"greedy\"\n",
    "\n",
    "run=\"debug\"\n",
    "noise_eps, pgd_eps, iters=2, 0.5, 10\n",
    "\n",
    "start_from=25\n",
    "milestones=[50, 100, 150]\n",
    "\n",
    "# runwandb=wandb.init(\n",
    "#       # Set the project where this run will be logged\n",
    "#       project=\"test4\", \n",
    "#       # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "#       name=f\"{run}\", \n",
    "#       # Track hyperparameters and run metadata\n",
    "#       config={\n",
    "#     \"learning_rate\": lr,\n",
    "#     \"epochs\": epochs,\n",
    "#     \"batch_size\": batch_size,\n",
    "#     \"dataset_name\":dataset_name,\n",
    "#     \"prevent_stategic_output_decline\": prevent_stategic_output_decline,\n",
    "#     \"prevent_stategic_weight_increase\": prevent_stategic_weight_increase,\n",
    "#     \"self_interest_neurons\":self_interest_neurons,\n",
    "#     \"model_hidden_states\": hidden_states,\n",
    "#     \"noise_eps\": noise_eps, \n",
    "#     \"pgd_eps\": pgd_eps, \n",
    "#     \"iters\":iters,\n",
    "#     \"milestones\":milestones,\n",
    "#     \"after_start_prevent_stategic_weight_increase\": after_start_prevent_stategic_weight_increase,\n",
    "#     \"after_start_self_interest_neurons\": after_start_self_interest_neurons,\n",
    "#     \"start_from\":start_from,\n",
    "#     \"self_interest_layer\":self_interest_layer\n",
    "#     })"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:11.170359Z",
     "iopub.execute_input": "2022-12-30T20:19:11.170640Z",
     "iopub.status.idle": "2022-12-30T20:19:11.177081Z",
     "shell.execute_reply.started": "2022-12-30T20:19:11.170614Z",
     "shell.execute_reply": "2022-12-30T20:19:11.176130Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# datasets\n",
    "mean = {\n",
    "    'MNIST': np.array([0.1307]),\n",
    "    'FashionMNIST': np.array([0.2859])\n",
    "}\n",
    "std = {\n",
    "    'MNIST': 0.3081,\n",
    "    'FashionMNIST': 0.2859\n",
    "}\n",
    "train_transforms = {\n",
    "    'MNIST': [transforms.RandomCrop(28, padding=1, padding_mode='edge')],\n",
    "    'FashionMNIST': [transforms.RandomCrop(28, padding=1, padding_mode='edge')]\n",
    "}\n",
    "\n",
    "dataset_class = torchvision.datasets.FashionMNIST\n",
    "default_transform = [transforms.ToTensor(),\n",
    "                     transforms.Normalize(mean[dataset_name], [std[dataset_name]] * len(mean[dataset_name]))]\n",
    "\n",
    "train_transform = transforms.Compose(train_transforms[dataset_name] + default_transform)\n",
    "test_transform = transforms.Compose(default_transform)\n",
    "# build data sets\n",
    "trainDataset = dataset_class(root=\"./data\", train=True, transform=train_transform, download=True)\n",
    "testDataset = dataset_class(root=\"./data\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "# build data loaders\n",
    "trainDataloader = DataLoader(trainDataset,\n",
    "                             batch_size=batch_size, num_workers=1, sampler=None, drop_last=True, shuffle=True)\n",
    "\n",
    "testDataloader = DataLoader(testDataset, \n",
    "                            batch_size=batch_size, num_workers=1, sampler=None, drop_last=True, shuffle=True)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:11.279281Z",
     "iopub.execute_input": "2022-12-30T20:19:11.280011Z",
     "iopub.status.idle": "2022-12-30T20:19:11.367160Z",
     "shell.execute_reply.started": "2022-12-30T20:19:11.279977Z",
     "shell.execute_reply": "2022-12-30T20:19:11.366163Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model\n",
    "class ClassifierMLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_layer_size, class_num, mode):\n",
    "        super(ClassifierMLP, self).__init__()\n",
    "        layers = []\n",
    "        input_size = 784\n",
    "        self.mode=mode\n",
    "        for i, h in enumerate(hidden_layer_size):\n",
    "            layers.append(GLinear(input_size, h, mode, nn.ReLU()))\n",
    "            input_size = h\n",
    "        layers.append(GLinear(input_size, class_num, mode, None))\n",
    "        self.deep = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x=self.deep(x)\n",
    "        return x"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:11.376256Z",
     "iopub.execute_input": "2022-12-30T20:19:11.376543Z",
     "iopub.status.idle": "2022-12-30T20:19:11.385473Z",
     "shell.execute_reply.started": "2022-12-30T20:19:11.376516Z",
     "shell.execute_reply": "2022-12-30T20:19:11.384461Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# change model state\n",
    "def set_to_eval(model):\n",
    "    model.eval()\n",
    "            \n",
    "\n",
    "def set_to_train(model):\n",
    "    model.train()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:11.550744Z",
     "iopub.execute_input": "2022-12-30T20:19:11.551047Z",
     "iopub.status.idle": "2022-12-30T20:19:11.555699Z",
     "shell.execute_reply.started": "2022-12-30T20:19:11.551021Z",
     "shell.execute_reply": "2022-12-30T20:19:11.554613Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# PGD Attack\n",
    "# datasets\n",
    "pgd_mean = {\n",
    "    'MNIST': np.array([0.1307]),\n",
    "    'FashionMNIST': np.array([0.2859])\n",
    "}\n",
    "pgd_std = {\n",
    "    'MNIST': 0.3081,\n",
    "    'FashionMNIST': 0.2859\n",
    "}\n",
    "def pgd_attack(model, images, labels, eps=0.3, alpha=2/255, iters=40, t=1):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    ori_images = images.data\n",
    "    min_val=((0-pgd_mean[dataset_name][0])/pgd_std[dataset_name])\n",
    "    max_val=(1-pgd_mean[dataset_name][0])/pgd_mean[dataset_name][0]\n",
    "    for i in range(iters) :    \n",
    "        images.requires_grad = True\n",
    "        outputs = model(images, t)\n",
    "\n",
    "        model.zero_grad()\n",
    "        cost = loss(outputs, labels).to(device)\n",
    "        cost.backward()\n",
    "\n",
    "        adv_images = images + alpha*images.grad.sign()\n",
    "        eta = torch.clamp(adv_images - ori_images, min=-eps, max=eps)\n",
    "        images = torch.clamp(ori_images + eta, min=min_val, max=max_val).detach_()\n",
    "            \n",
    "    return images\n",
    "\n",
    "def add_noise(images, eps):\n",
    "    min_val=((0-pgd_mean[dataset_name][0])/pgd_std[dataset_name])\n",
    "    max_val=(1-pgd_mean[dataset_name][0])/pgd_std[dataset_name]\n",
    "    eta=torch.normal(0.0, eps/2, images.shape, device=device)\n",
    "    images = torch.clamp(images + eta, min=min_val, max=max_val).detach_() \n",
    "    return images"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:11.664229Z",
     "iopub.execute_input": "2022-12-30T20:19:11.664987Z",
     "iopub.status.idle": "2022-12-30T20:19:11.675278Z",
     "shell.execute_reply.started": "2022-12-30T20:19:11.664953Z",
     "shell.execute_reply": "2022-12-30T20:19:11.674014Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def track_model(model, epoch, step=0):\n",
    "    for name, param in model.named_parameters():\n",
    "        try:\n",
    "            if len(param.data.shape)==1:\n",
    "                wandb.log({f\"w_{name}_norm2\":torch.linalg.norm(param.data) , 'epoch': epoch, 'batch': step})\n",
    "                wandb.log({f\"grad_{name}_norm2\":torch.linalg.norm(param.grad) , 'epoch': epoch, 'batch': step})\n",
    "            else:\n",
    "                wandb.log({f\"w_{name}_norm2\":torch.linalg.matrix_norm(param.data) , 'epoch': epoch, 'batch': step})\n",
    "                wandb.log({f\"grad_{name}_norm2\":torch.linalg.matrix_norm(param.grad) , 'epoch': epoch, 'batch': step})\n",
    "        except:\n",
    "            pass\n",
    "#                 print(name)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:11.755408Z",
     "iopub.execute_input": "2022-12-30T20:19:11.755676Z",
     "iopub.status.idle": "2022-12-30T20:19:11.762383Z",
     "shell.execute_reply.started": "2022-12-30T20:19:11.755643Z",
     "shell.execute_reply": "2022-12-30T20:19:11.761490Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def normal_eval(model, testDataloader, epoch, loss_func):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        loss = 0\n",
    "        for step, (x, y) in enumerate(testDataloader):\n",
    "            # forward pass\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss_c = loss_func(output, y)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            loss += loss_c.detach().item()\n",
    "            total += x.shape[0]\n",
    "            correct += torch.sum(y == output).detach().item()\n",
    "\n",
    "        acc=(correct / total)\n",
    "        loss=loss / len(testDataloader)\n",
    "#         wandb.log({\"test_loss\": loss,'epoch': epoch})\n",
    "#         wandb.log({\"accuracy\": acc,'epoch': epoch})\n",
    "        print(f'normal accuracy={round(acc, 3)}, loss={round(loss, 3)}')\n",
    "        \n",
    "def robust_eval(model, testDataloader, epoch, loss_func, eps, iters, t=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    for step, (x, y) in enumerate(testDataloader):\n",
    "        # forward pass\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x=pgd_attack(model, x, y, eps=eps, alpha=(eps/iters)*2.5, iters=iters, t=t)\n",
    "        with torch.no_grad():\n",
    "            output = model(x)\n",
    "            loss_c = loss_func(output, y)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            loss += loss_c.detach().item()\n",
    "            total += x.shape[0]\n",
    "            correct += torch.sum(y == output).detach().item()\n",
    "\n",
    "    acc=(correct / total)\n",
    "    loss=loss / len(testDataloader)\n",
    "    if t==1:\n",
    "        wandb.log({\"robust_test_loss\": loss,'epoch': epoch})\n",
    "        wandb.log({\"robust_accuracy\": acc,'epoch': epoch})\n",
    "        print(f'robust accuracy={round(acc, 3)}, loss={round(loss, 3)}')\n",
    "    else:\n",
    "        return acc, loss\n",
    "    \n",
    "def strong_robust_eval(model, testDataloader, epoch, loss_func, eps, iters):\n",
    "    t=0.001\n",
    "    while t<100:\n",
    "        t*=2\n",
    "        if t!=1:\n",
    "            acc, loss=robust_eval(model, testDataloader, epoch, loss_func, eps, iters, t)\n",
    "            wandb.log({\"robust_test_loss_t\": loss,'t': t})\n",
    "            wandb.log({\"robust_accuracy\": acc,'t': t})\n",
    "            print(f'robust accuracy={round(acc, 3)}, loss={round(loss, 3)}, t={t}, steps={iters}')\n",
    "    \n",
    "def noise_robust_eval(model, testDataloader, epoch, loss_func, eps):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    for step, (x, y) in enumerate(testDataloader):\n",
    "        # forward pass\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x=add_noise(x, eps=eps)\n",
    "        with torch.no_grad():\n",
    "            output = model(x)\n",
    "            loss_c = loss_func(output, y)\n",
    "            output = torch.argmax(output, dim=1)\n",
    "            loss += loss_c.detach().item()\n",
    "            total += x.shape[0]\n",
    "            correct += torch.sum(y == output).detach().item()\n",
    "\n",
    "    acc=(correct / total)\n",
    "    loss=loss / len(testDataloader)\n",
    "    wandb.log({\"noise robust_test_loss\": loss,'epoch': epoch})\n",
    "    wandb.log({\"noise robust_accuracy\": acc,'epoch': epoch})\n",
    "    print(f'noise robust accuracy={round(acc, 3)}, loss={round(loss, 3)}')\n",
    "\n",
    "    \n",
    "def check_cos_similarity(model, testDataloader, loss_func, layer):\n",
    "    testing_model = ClassifierMLP(hidden_states, 10, prevent_stategic_output_decline, prevent_stategic_weight_increase, self_interest_neurons).to(device)\n",
    "    testing_model.load_state_dict(model.state_dict())\n",
    "    testing_optimizer = torch.optim.SGD(params=testing_model.parameters(), lr=0.0001)\n",
    "    testing_optimizer.zero_grad()\n",
    "    tx=None\n",
    "    for x, y in testDataloader:\n",
    "        x= x.to(device)\n",
    "        tx= x\n",
    "        break\n",
    "    y=testing_model.assumsion_check_forward(tx, layer, 0)\n",
    "    ty=torch.normal(0.0, 3, y.shape, device=device)\n",
    "    loss=torch.sum((y*ty))\n",
    "    \n",
    "    loss.backward()\n",
    "    testing_optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        new_y=testing_model.assumsion_check_forward(tx, layer, 0)\n",
    "        diff=new_y-y\n",
    "        ty=ty/torch.sum(ty*ty)\n",
    "        diff=diff/torch.sum(diff*diff)\n",
    "        cos=torch.sum(ty*diff)\n",
    "        return cos.cpu().item()\n",
    "        \n",
    "def assumsion_check(model, testDataloader, loss_func):\n",
    "    for i in range(1,7):\n",
    "        cos_i=check_cos_similarity(model, testDataloader, loss_func, i)\n",
    "        print(f\"cos_{i}={cos_i}\")\n",
    "        wandb.log({f\"cos_{i}\": cos_i,'epoch': epoch, 'batch': step})\n",
    "        \n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:15.545270Z",
     "iopub.execute_input": "2022-12-30T20:19:15.545572Z",
     "iopub.status.idle": "2022-12-30T20:19:15.570359Z",
     "shell.execute_reply.started": "2022-12-30T20:19:15.545544Z",
     "shell.execute_reply": "2022-12-30T20:19:15.569402Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_21708\\1391650151.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"cuda\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mClassifierMLP\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"greedy\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mscheduler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlr_scheduler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMultiStepLR\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmilestones\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmilestones\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# for name, param in model.named_parameters():\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mto\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    897\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 899\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    900\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    901\u001B[0m     def register_backward_hook(\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    591\u001B[0m             \u001B[1;31m# `with torch.no_grad():`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 593\u001B[1;33m                 \u001B[0mparam_applied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    594\u001B[0m             \u001B[0mshould_use_set_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mconvert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    895\u001B[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001B[0;32m    896\u001B[0m                             non_blocking, memory_format=convert_to_format)\n\u001B[1;32m--> 897\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    898\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    899\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\cuda\\__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    206\u001B[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001B[0;32m    207\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'_cuda_getDeviceCount'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Torch not compiled with CUDA enabled\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_cudart\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             raise AssertionError(\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "model = ClassifierMLP(hidden_states, 10, \"greedy\").to(device)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name)\n",
    "# print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss_func=torch.nn.CrossEntropyLoss()\n",
    "epoch=0"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-30T20:19:15.573734Z",
     "iopub.execute_input": "2022-12-30T20:19:15.574079Z",
     "iopub.status.idle": "2022-12-30T20:19:15.580539Z",
     "shell.execute_reply.started": "2022-12-30T20:19:15.574052Z",
     "shell.execute_reply": "2022-12-30T20:19:15.579551Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(0,epochs):\n",
    "#     if epoch==start_from:\n",
    "#         model.self_interest_neurons=after_start_self_interest_neurons\n",
    "#         model.prevent_stategic_weight_increase=after_start_prevent_stategic_weight_increase\n",
    "#         self_interest_neurons=after_start_self_interest_neurons\n",
    "#         prevent_stategic_weight_increase=after_start_prevent_stategic_weight_increase\n",
    "        \n",
    "    set_to_train(model)\n",
    "    avgloss = 0\n",
    "    with tqdm(total=len(trainDataloader), position=0, leave=False) as pbar:\n",
    "        for step, (x, y) in enumerate(trainDataloader):\n",
    "            # forward pass\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = loss_func(output, y)\n",
    "            print(f\"loss:{loss}\")\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update()\n",
    "                \n",
    "#             if step==int(len(trainDataloader)/2):\n",
    "#                 model.normalize_weights()\n",
    "                \n",
    "            #tracking\n",
    "            avgloss += loss.detach().item()\n",
    "            if step%10==1:\n",
    "                optimizer.zero_grad()\n",
    "#                 model.normalize_weights()\n",
    "                \n",
    "            if step%40==1:\n",
    "                print(f\"train_loss:{avgloss/40}  epoch:{epoch}, batch:{step}\")\n",
    "#                 wandb.log({\"train_loss\": avgloss/20,'epoch': epoch, 'batch': step})\n",
    "                avgloss=0\n",
    "                \n",
    "#             if step==0:\n",
    "#                 track_model(model, epoch)\n",
    "    scheduler.step()\n",
    "#     wandb.log({\"learning_rate_plot\": scheduler.get_last_lr()[-1],'epoch': epoch})\n",
    "#     optimizer.zero_grad()\n",
    "#     model.normalize_weights()\n",
    "#     set_to_eval(model)\n",
    "    # normal_eval(model, testDataloader, epoch, loss_func)\n",
    "#     robust_eval(model, testDataloader, epoch, loss_func, pgd_eps, iters)  \n",
    "#     noise_robust_eval(model, testDataloader, epoch, loss_func, noise_eps)\n",
    "#     set_to_train(model)\n",
    "#     assumsion_check(model, testDataloader, loss_func)  "
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": 116,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.299886465072632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/117 [00:11<21:38, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.30244517326355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/117 [00:20<18:48,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:0.11505829095840454  epoch:0, batch:1\n",
      "loss:2.3009252548217773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/117 [00:28<17:46,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.3012654781341553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/117 [00:37<17:11,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.2973484992980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_106484\\3465520653.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"loss:{loss}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m             \u001B[1;31m# backward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m             \u001B[0mpbar\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    306\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 307\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    154\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 156\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    157\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\function.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mBackwardCFunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_FunctionBase\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFunctionCtx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_HookMixin\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 189\u001B[1;33m     \u001B[1;32mdef\u001B[0m \u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    190\u001B[0m         \u001B[1;31m# _forward_cls is defined by derived class\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    191\u001B[0m         \u001B[1;31m# The user should define either backward or vjp but never both.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# best_weights=wandb.restore('final_model_199.pt', run_path=\"ckodserteam/test3/3sem9zdl\")\n# print(best_weights.name)\n# st=torch.load(best_weights.name)\n# model.load_state_dict(st)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# set_to_eval(model)\n# normal_eval(model, testDataloader, epoch, loss_func)\n# robust_eval(model, testDataloader, epoch, loss_func, pgd_eps, iters)  \n# noise_robust_eval(model, testDataloader, epoch, loss_func, noise_eps)\n# set_to_train(model)\n# assumsion_check(model, testDataloader, loss_func)  ",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# set_to_eval(model)\n# strong_robust_eval(model, testDataloader, epoch, loss_func, pgd_eps, iters)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# torch.save(model.state_dict(),os.path.join(wandb.run.dir, f\"final_model_{epoch}.pt\"))\n# wandb.save(f\"final_model_{epoch}.pt\")\n        \n# runwandb.finish()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}